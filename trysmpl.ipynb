{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset.mesh_util import *\n",
    "#from lib.smplx.body_models import SMPLX\n",
    "from lib.dataset.TestDataset import TestDataset\n",
    "from lib.common.config import cfg\n",
    "from lib.pymafx.core import path_config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMPLX_object = SMPLX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of each parameter in 'dataset_param':\n",
    "\n",
    "    <class 'str'>\n",
    "    <class 'NoneType'>\n",
    "    <class 'bool'>\n",
    "    <class 'str'>\n",
    "    <class 'int'>\n",
    "    <class 'bool'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_param = {\n",
    "        \"image_dir\": './examples/testimg/',\n",
    "        \"seg_dir\": None,\n",
    "        \"use_seg\": True,    # w/ or w/o segmentation\n",
    "        \"hps_type\": 'pymafx' ,   # pymafx/pixie\n",
    "        \"vol_res\": cfg.vol_res,\n",
    "        \"single\": False, #args.multi,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_config.pymafx_data_dir = \"./data/HPS/pymafx_data\"\n",
    "\n",
    "os.path.exists(path_config.pymafx_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "param_npz = np.load('./00006_0.npz' , allow_pickle=True)\n",
    "print(type(param_npz))\n",
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {key: torch.as_tensor(param_npz[key]) for key in param_npz.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in param.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.infer import view_dict_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient: torch.Size([1, 3])\n",
      "body_pose: torch.Size([21, 3])\n",
      "left_hand_pose: torch.Size([15, 3])\n",
      "right_hand_pose: torch.Size([15, 3])\n",
      "jaw_pose: torch.Size([1, 3])\n",
      "leye_pose: torch.Size([1, 3])\n",
      "reye_pose: torch.Size([1, 3])\n",
      "betas: torch.Size([1, 10])\n",
      "expression: torch.Size([1, 10])\n",
      "transl: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "view_dict_items(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMPLX_object = SMPLX('00006_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient :  (1, 3)\n",
      "body_pose :  (21, 3)\n",
      "left_hand_pose :  (15, 3)\n",
      "right_hand_pose :  (15, 3)\n",
      "jaw_pose :  (1, 3)\n",
      "leye_pose :  (1, 3)\n",
      "reye_pose :  (1, 3)\n",
      "betas :  (1, 10)\n",
      "expression :  (1, 10)\n",
      "transl :  (1, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./results/econ/obj/000023.jpg_0.npz',allow_pickle=True)\n",
    "#print(data)\n",
    "#data= data.tolist()\n",
    "for item in data:\n",
    "    print(item,': ',data[item].shape)\n",
    "\n",
    "#print(data['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "npyfile = './pymafx_results/econ/obj/OIP_smpl_00.npy'\n",
    "NpzFile = './00006_0.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(NpzFile, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "for item in data :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.kornia.axis2matrix import axis_angle_to_rotation_matrix\n",
    "from lib.kornia.core import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_jaw = axis_angle_to_rotation_matrix( Tensor(data['jaw_pose']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000e+00,  5.4224e-04, -2.6588e-03],\n",
      "         [-5.8650e-04,  9.9986e-01, -1.6671e-02],\n",
      "         [ 2.6494e-03,  1.6673e-02,  9.9986e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(matrix_jaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas torch.Size([1, 20])\n",
      "shape_disps torch.Size([10475, 3, 20])\n",
      "J torch.Size([1, 55, 3])\n",
      "ident torch.Size([3, 3])\n",
      "pose_feature torch.Size([1, 1476])\n",
      "posedirs torch.Size([486, 31425])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1476 and 486x31425)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m smpl_mesh,smpl_joint \u001b[39m=\u001b[39m load_fit_body(fitted_path\u001b[39m=\u001b[39;49mNpzFile,scale\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/ECON/lib/dataset/mesh_util.py:241\u001b[0m, in \u001b[0;36mload_fit_body\u001b[0;34m(fitted_path, scale, smpl_type, smpl_gender, noise_dict)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39mif\u001b[39;00m noise_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     model_forward_params\u001b[39m.\u001b[39mupdate(noise_dict)\n\u001b[0;32m--> 241\u001b[0m smpl_out \u001b[39m=\u001b[39m smpl_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_forward_params)\n\u001b[1;32m    243\u001b[0m smpl_verts \u001b[39m=\u001b[39m ((smpl_out\u001b[39m.\u001b[39mvertices[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m scale)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m    244\u001b[0m smpl_joints \u001b[39m=\u001b[39m ((smpl_out\u001b[39m.\u001b[39mjoints[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m scale)\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniforge3/envs/econ/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ECON/lib/smplx/body_models.py:1348\u001b[0m, in \u001b[0;36mSMPLX.forward\u001b[0;34m(self, betas, global_orient, body_pose, left_hand_pose, right_hand_pose, transl, expression, jaw_pose, leye_pose, reye_pose, return_verts, return_full_pose, pose2rot, return_joint_transformation, return_vertex_transformation, pose_type, **kwargs)\u001b[0m\n\u001b[1;32m   1335\u001b[0m     vertices, joints, joint_transformation, vertex_transformation \u001b[39m=\u001b[39m lbs(\n\u001b[1;32m   1336\u001b[0m         shape_components,\n\u001b[1;32m   1337\u001b[0m         full_pose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         return_transformation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1346\u001b[0m     )\n\u001b[1;32m   1347\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     vertices, joints \u001b[39m=\u001b[39m lbs(\n\u001b[1;32m   1349\u001b[0m         shape_components,\n\u001b[1;32m   1350\u001b[0m         full_pose,\n\u001b[1;32m   1351\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mv_template,\n\u001b[1;32m   1352\u001b[0m         shapedirs,\n\u001b[1;32m   1353\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mposedirs,\n\u001b[1;32m   1354\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mJ_regressor,\n\u001b[1;32m   1355\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparents,\n\u001b[1;32m   1356\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlbs_weights,\n\u001b[1;32m   1357\u001b[0m         pose2rot\u001b[39m=\u001b[39;49mpose2rot,\n\u001b[1;32m   1358\u001b[0m     )\n\u001b[1;32m   1360\u001b[0m lmk_faces_idx \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlmk_faces_idx\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mexpand(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcontiguous())\n\u001b[1;32m   1361\u001b[0m lmk_bary_coords \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlmk_bary_coords\u001b[39m.\u001b[39munsqueeze(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/ECON/lib/smplx/lbs.py:214\u001b[0m, in \u001b[0;36mlbs\u001b[0;34m(betas, pose, v_template, shapedirs, posedirs, J_regressor, parents, lbs_weights, pose2rot, return_transformation)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpose_feature\u001b[39m\u001b[39m'\u001b[39m, pose_feature\u001b[39m.\u001b[39mshape)\n\u001b[1;32m    213\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mposedirs\u001b[39m\u001b[39m'\u001b[39m,posedirs\u001b[39m.\u001b[39mshape)\n\u001b[0;32m--> 214\u001b[0m     pose_offsets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(pose_feature, posedirs)\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     pose_feature \u001b[39m=\u001b[39m pose[:, \u001b[39m1\u001b[39m:]\u001b[39m.\u001b[39mview(batch_size, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m) \u001b[39m-\u001b[39m ident\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1476 and 486x31425)"
     ]
    }
   ],
   "source": [
    "smpl_mesh,smpl_joint = load_fit_body(fitted_path=NpzFile,scale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
