{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from lib.dataset.mesh_util import *\n",
    "#from lib.smplx.body_models import SMPLX\n",
    "from lib.dataset.TestDataset import TestDataset\n",
    "from lib.common.config import cfg\n",
    "from lib.pymafx.core import path_config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMPLX_object = SMPLX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of each parameter in 'dataset_param':\n",
    "\n",
    "    <class 'str'>\n",
    "    <class 'NoneType'>\n",
    "    <class 'bool'>\n",
    "    <class 'str'>\n",
    "    <class 'int'>\n",
    "    <class 'bool'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_param = {\n",
    "        \"image_dir\": './examples/testimg/',\n",
    "        \"seg_dir\": None,\n",
    "        \"use_seg\": True,    # w/ or w/o segmentation\n",
    "        \"hps_type\": 'pymafx' ,   # pymafx/pixie\n",
    "        \"vol_res\": cfg.vol_res,\n",
    "        \"single\": False, #args.multi,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_config.pymafx_data_dir = \"./data/HPS/pymafx_data\"\n",
    "\n",
    "os.path.exists(path_config.pymafx_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "param_npz = np.load('./00006_0.npz' , allow_pickle=True)\n",
    "print(type(param_npz))\n",
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {key: torch.as_tensor(param_npz[key]) for key in param_npz.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in param.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.infer import view_dict_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient: torch.Size([1, 3])\n",
      "body_pose: torch.Size([21, 3])\n",
      "left_hand_pose: torch.Size([15, 3])\n",
      "right_hand_pose: torch.Size([15, 3])\n",
      "jaw_pose: torch.Size([1, 3])\n",
      "leye_pose: torch.Size([1, 3])\n",
      "reye_pose: torch.Size([1, 3])\n",
      "betas: torch.Size([1, 10])\n",
      "expression: torch.Size([1, 10])\n",
      "transl: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "view_dict_items(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMPLX_object = SMPLX('00006_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient :  (1, 3)\n",
      "body_pose :  (21, 3)\n",
      "left_hand_pose :  (15, 3)\n",
      "right_hand_pose :  (15, 3)\n",
      "jaw_pose :  (1, 3)\n",
      "leye_pose :  (1, 3)\n",
      "reye_pose :  (1, 3)\n",
      "betas :  (1, 10)\n",
      "expression :  (1, 10)\n",
      "transl :  (1, 3)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'scale is not a file in the archive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m data:\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(item,\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m,data[item]\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 7\u001b[0m \u001b[39mprint\u001b[39m(data[\u001b[39m'\u001b[39;49m\u001b[39mscale\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniforge3/envs/econ/lib/python3.8/site-packages/numpy/lib/npyio.py:251\u001b[0m, in \u001b[0;36mNpzFile.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mzip\u001b[39m.\u001b[39mread(key)\n\u001b[1;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not a file in the archive\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'scale is not a file in the archive'"
     ]
    }
   ],
   "source": [
    "data = np.load('./results/econ/obj/000023.jpg_0.npz',allow_pickle=True)\n",
    "#print(data)\n",
    "#data= data.tolist()\n",
    "for item in data:\n",
    "    print(item,': ',data[item].shape)\n",
    "\n",
    "print(data['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "npyfile = './pymafx_results/econ/obj/OIP_smpl_00.npy'\n",
    "NpzFile = './00006_0.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(npyfile,allow_pickle=True)\n",
    "data = data.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas\n",
      "body_pose\n",
      "global_orient\n",
      "transl\n",
      "expression\n",
      "jaw_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "scale\n"
     ]
    }
   ],
   "source": [
    "for item in data :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'leye_pose'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m smpl_mesh,smpl_joint \u001b[39m=\u001b[39m load_fit_body(fitted_path\u001b[39m=\u001b[39;49mnpyfile,scale\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/ECON/lib/dataset/mesh_util.py:226\u001b[0m, in \u001b[0;36mload_fit_body\u001b[0;34m(fitted_path, scale, smpl_type, smpl_gender, noise_dict)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m# for key in param.keys():\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[39m#     param[key] = torch.as_tensor(param[key])\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[39m#get the original model 获得原始模型\u001b[39;00m\n\u001b[1;32m    217\u001b[0m smpl_model \u001b[39m=\u001b[39m get_smpl_model(smpl_type, smpl_gender)\n\u001b[1;32m    219\u001b[0m model_forward_params \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m    220\u001b[0m     betas\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    221\u001b[0m     global_orient\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mglobal_orient\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    222\u001b[0m     body_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mbody_pose\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    223\u001b[0m     left_hand_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mleft_hand_pose\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    224\u001b[0m     right_hand_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mright_hand_pose\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    225\u001b[0m     jaw_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mjaw_pose\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[0;32m--> 226\u001b[0m     leye_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39;49m\u001b[39mleye_pose\u001b[39;49m\u001b[39m\"\u001b[39;49m] ,\n\u001b[1;32m    227\u001b[0m     reye_pose\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mreye_pose\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    228\u001b[0m     expression\u001b[39m=\u001b[39mparam[\u001b[39m\"\u001b[39m\u001b[39mexpression\u001b[39m\u001b[39m\"\u001b[39m] ,\n\u001b[1;32m    229\u001b[0m     return_verts\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    230\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m noise_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     model_forward_params\u001b[39m.\u001b[39mupdate(noise_dict)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'leye_pose'"
     ]
    }
   ],
   "source": [
    "smpl_mesh,smpl_joint = load_fit_body(fitted_path=npyfile,scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_angle_to_rotation_matrix(axis_angle: Tensor) -> Tensor:\n",
    "    r\"\"\"Convert 3d vector of axis-angle rotation to 3x3 rotation matrix.\n",
    "\n",
    "    Args:\n",
    "        axis_angle: tensor of 3d vector of axis-angle rotations in radians with shape :math:`(N, 3)`.\n",
    "\n",
    "    Returns:\n",
    "        tensor of rotation matrices of shape :math:`(N, 3, 3)`.\n",
    "\n",
    "    Example:\n",
    "        >>> input = tensor([[0., 0., 0.]])\n",
    "        >>> axis_angle_to_rotation_matrix(input)\n",
    "        tensor([[[1., 0., 0.],\n",
    "                 [0., 1., 0.],\n",
    "                 [0., 0., 1.]]])\n",
    "\n",
    "        >>> input = tensor([[1.5708, 0., 0.]])\n",
    "        >>> axis_angle_to_rotation_matrix(input)\n",
    "        tensor([[[ 1.0000e+00,  0.0000e+00,  0.0000e+00],\n",
    "                 [ 0.0000e+00, -3.6200e-06, -1.0000e+00],\n",
    "                 [ 0.0000e+00,  1.0000e+00, -3.6200e-06]]])\n",
    "    \"\"\"\n",
    "    if not isinstance(axis_angle, Tensor):\n",
    "        raise TypeError(f\"Input type is not a Tensor. Got {type(axis_angle)}\")\n",
    "\n",
    "    if not axis_angle.shape[-1] == 3:\n",
    "        raise ValueError(f\"Input size must be a (*, 3) tensor. Got {axis_angle.shape}\")\n",
    "\n",
    "    def _compute_rotation_matrix(axis_angle: Tensor, theta2: Tensor, eps: float = 1e-6) -> Tensor:\n",
    "        # We want to be careful to only evaluate the square root if the\n",
    "        # norm of the axis_angle vector is greater than zero. Otherwise\n",
    "        # we get a division by zero.\n",
    "        k_one = 1.0\n",
    "        theta = torch.sqrt(theta2)\n",
    "        wxyz = axis_angle / (theta + eps)\n",
    "        wx, wy, wz = torch.chunk(wxyz, 3, dim=1)\n",
    "        cos_theta = cos(theta)\n",
    "        sin_theta = sin(theta)\n",
    "\n",
    "        r00 = cos_theta + wx * wx * (k_one - cos_theta)\n",
    "        r10 = wz * sin_theta + wx * wy * (k_one - cos_theta)\n",
    "        r20 = -wy * sin_theta + wx * wz * (k_one - cos_theta)\n",
    "        r01 = wx * wy * (k_one - cos_theta) - wz * sin_theta\n",
    "        r11 = cos_theta + wy * wy * (k_one - cos_theta)\n",
    "        r21 = wx * sin_theta + wy * wz * (k_one - cos_theta)\n",
    "        r02 = wy * sin_theta + wx * wz * (k_one - cos_theta)\n",
    "        r12 = -wx * sin_theta + wy * wz * (k_one - cos_theta)\n",
    "        r22 = cos_theta + wz * wz * (k_one - cos_theta)\n",
    "        rotation_matrix = concatenate([r00, r01, r02, r10, r11, r12, r20, r21, r22], dim=1)\n",
    "        return rotation_matrix.view(-1, 3, 3)\n",
    "\n",
    "    def _compute_rotation_matrix_taylor(axis_angle: Tensor) -> Tensor:\n",
    "        rx, ry, rz = torch.chunk(axis_angle, 3, dim=1)\n",
    "        k_one = torch.ones_like(rx)\n",
    "        rotation_matrix = concatenate([k_one, -rz, ry, rz, k_one, -rx, -ry, rx, k_one], dim=1)\n",
    "        return rotation_matrix.view(-1, 3, 3)\n",
    "\n",
    "    # stolen from ceres/rotation.h\n",
    "\n",
    "    _axis_angle = torch.unsqueeze(axis_angle, dim=1)\n",
    "    theta2 = torch.matmul(_axis_angle, _axis_angle.transpose(1, 2))\n",
    "    theta2 = torch.squeeze(theta2, dim=1)\n",
    "\n",
    "    # compute rotation matrices\n",
    "    rotation_matrix_normal = _compute_rotation_matrix(axis_angle, theta2)\n",
    "    rotation_matrix_taylor = _compute_rotation_matrix_taylor(axis_angle)\n",
    "\n",
    "    # create mask to handle both cases\n",
    "    eps = 1e-6\n",
    "    mask = (theta2 > eps).view(-1, 1, 1).to(theta2.device)\n",
    "    mask_pos = (mask).type_as(theta2)\n",
    "    mask_neg = (~mask).type_as(theta2)\n",
    "\n",
    "    # create output pose matrix with masked values\n",
    "    rotation_matrix = mask_pos * rotation_matrix_normal + mask_neg * rotation_matrix_taylor\n",
    "    return rotation_matrix  # Nx3x3\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
