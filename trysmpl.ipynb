{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from lib.dataset.mesh_util import *\n",
    "#from lib.smplx.body_models import SMPLX\n",
    "from lib.dataset.TestDataset import TestDataset\n",
    "from lib.common.config import cfg\n",
    "from lib.pymafx.core import path_config\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMPLX_object = SMPLX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type of each parameter in 'dataset_param':\n",
    "\n",
    "    <class 'str'>\n",
    "    <class 'NoneType'>\n",
    "    <class 'bool'>\n",
    "    <class 'str'>\n",
    "    <class 'int'>\n",
    "    <class 'bool'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_param = {\n",
    "        \"image_dir\": './examples/testimg/',\n",
    "        \"seg_dir\": None,\n",
    "        \"use_seg\": True,    # w/ or w/o segmentation\n",
    "        \"hps_type\": 'pymafx' ,   # pymafx/pixie\n",
    "        \"vol_res\": cfg.vol_res,\n",
    "        \"single\": False, #args.multi,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_config.pymafx_data_dir = \"./data/HPS/pymafx_data\"\n",
    "\n",
    "os.path.exists(path_config.pymafx_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.lib.npyio.NpzFile'>\n",
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "param_npz = np.load('./00006_0.npz' , allow_pickle=True)\n",
    "print(type(param_npz))\n",
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {key: torch.as_tensor(param_npz[key]) for key in param_npz.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "for item in param_npz:\n",
    "    print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key in param.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apps.infer import view_dict_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient: torch.Size([1, 3])\n",
      "body_pose: torch.Size([21, 3])\n",
      "left_hand_pose: torch.Size([15, 3])\n",
      "right_hand_pose: torch.Size([15, 3])\n",
      "jaw_pose: torch.Size([1, 3])\n",
      "leye_pose: torch.Size([1, 3])\n",
      "reye_pose: torch.Size([1, 3])\n",
      "betas: torch.Size([1, 10])\n",
      "expression: torch.Size([1, 10])\n",
      "transl: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "view_dict_items(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMPLX_object = SMPLX('00006_0.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient :  (1, 3)\n",
      "body_pose :  (21, 3)\n",
      "left_hand_pose :  (15, 3)\n",
      "right_hand_pose :  (15, 3)\n",
      "jaw_pose :  (1, 3)\n",
      "leye_pose :  (1, 3)\n",
      "reye_pose :  (1, 3)\n",
      "betas :  (1, 10)\n",
      "expression :  (1, 10)\n",
      "transl :  (1, 3)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./results/econ/obj/000023.jpg_0.npz',allow_pickle=True)\n",
    "#print(data)\n",
    "#data= data.tolist()\n",
    "for item in data:\n",
    "    print(item,': ',data[item].shape)\n",
    "\n",
    "#print(data['scale'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "npyfile = './pymafx_results/econ/obj/OIP_smpl_00.npy'\n",
    "NpzFile = './00006_0.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(NpzFile, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_orient\n",
      "body_pose\n",
      "left_hand_pose\n",
      "right_hand_pose\n",
      "jaw_pose\n",
      "leye_pose\n",
      "reye_pose\n",
      "betas\n",
      "expression\n",
      "transl\n"
     ]
    }
   ],
   "source": [
    "for item in data :\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from axis2matrix import axis_angle_to_rotation_matrix\n",
    "from lib.kornia.core import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_jaw = axis_angle_to_rotation_matrix( Tensor(data['jaw_pose']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0000e+00,  5.4224e-04, -2.6588e-03],\n",
      "         [-5.8650e-04,  9.9986e-01, -1.6671e-02],\n",
      "         [ 2.6494e-03,  1.6673e-02,  9.9986e-01]]])\n"
     ]
    }
   ],
   "source": [
    "print(matrix_jaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "torch.Size([15, 3])\n",
      "global_orient:torch.Size([1, 3])\n",
      "body_pose:torch.Size([21, 3])\n",
      "jaw_pose:torch.Size([1, 3])\n",
      "leye_pose:torch.Size([1, 3])\n",
      "reye_pose:torch.Size([1, 3])\n",
      "left_hand_pose:torch.Size([15, 3])\n",
      "right_hand_pose:torch.Size([15, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 1 but got size 21 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m smpl_mesh,smpl_joint \u001b[39m=\u001b[39m load_fit_body(fitted_path\u001b[39m=\u001b[39;49mNpzFile,scale\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/ECON/lib/dataset/mesh_util.py:236\u001b[0m, in \u001b[0;36mload_fit_body\u001b[0;34m(fitted_path, scale, smpl_type, smpl_gender, noise_dict)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m noise_dict \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     model_forward_params\u001b[39m.\u001b[39mupdate(noise_dict)\n\u001b[0;32m--> 236\u001b[0m smpl_out \u001b[39m=\u001b[39m smpl_model(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_forward_params)\n\u001b[1;32m    238\u001b[0m smpl_verts \u001b[39m=\u001b[39m ((smpl_out\u001b[39m.\u001b[39mvertices[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m scale)\u001b[39m.\u001b[39mdetach()\n\u001b[1;32m    239\u001b[0m smpl_joints \u001b[39m=\u001b[39m ((smpl_out\u001b[39m.\u001b[39mjoints[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m param[\u001b[39m\"\u001b[39m\u001b[39mtranslation\u001b[39m\u001b[39m\"\u001b[39m]) \u001b[39m*\u001b[39m scale)\u001b[39m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/miniforge3/envs/econ/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/ECON/lib/smplx/body_models.py:1267\u001b[0m, in \u001b[0;36mSMPLX.forward\u001b[0;34m(self, betas, global_orient, body_pose, left_hand_pose, right_hand_pose, transl, expression, jaw_pose, leye_pose, reye_pose, return_verts, return_full_pose, pose2rot, return_joint_transformation, return_vertex_transformation, pose_type, **kwargs)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mleft_hand_pose:\u001b[39m\u001b[39m{\u001b[39;00mleft_hand_pose\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1265\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mright_hand_pose:\u001b[39m\u001b[39m{\u001b[39;00mright_hand_pose\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1267\u001b[0m full_pose \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat(\n\u001b[1;32m   1268\u001b[0m     [\n\u001b[1;32m   1269\u001b[0m         global_orient,\n\u001b[1;32m   1270\u001b[0m         body_pose,\n\u001b[1;32m   1271\u001b[0m         jaw_pose,\n\u001b[1;32m   1272\u001b[0m         leye_pose,\n\u001b[1;32m   1273\u001b[0m         reye_pose,\n\u001b[1;32m   1274\u001b[0m         left_hand_pose,\n\u001b[1;32m   1275\u001b[0m         right_hand_pose,\n\u001b[1;32m   1276\u001b[0m     ],\n\u001b[1;32m   1277\u001b[0m     \u001b[39m#dim=0,\u001b[39;49;00m\n\u001b[1;32m   1278\u001b[0m     dim \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1279\u001b[0m )\n\u001b[1;32m   1280\u001b[0m \u001b[39m#full_pose = full_pose.permute(1,0)\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[39mif\u001b[39;00m pose_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mt-pose\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 1 but got size 21 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "smpl_mesh,smpl_joint = load_fit_body(fitted_path=NpzFile,scale=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
